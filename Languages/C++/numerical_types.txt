
//==================================================================
// Binary Representation: 1. 2's Complement
//==================================================================
ECE2060 Lecture 3

https://stackoverflow.com/questions/1049722/what-is-2s-complement
It basically says,

1. for zero, use all 0's.
2. for positive integers, start counting up, with a maximum of 2(number of bits - 1)-1.
3. for negative integers, do exactly the same thing, but switch the role of 0's and 1's (so instead of starting 
with 0000, start with 1111 - that's the "complement" part).


--------------------------------------------------------------
[How to get?]
Assume:
	N	= 11001
	1's	= 00110

I. 2's Complement of N = 1's Complement of N + 1
	
		00110	//1's complement of N
	   +    1
	   ------
		00111	//2's complement of N
	
	1. handscript method:
		1. get binary representation
		2. from right to left, find the first 1
		3. flip all bits on the left
		(Ex: 0000 1000 -> 1111 1000)
		
	2. bitwise operation method:
		1. get binary representation
		2. flip all bits
		3. add 1 to it
		(Ex: ~x + 1)


II. 2's Complement of N = 
		- If N != 0: (2^n - N)	//n: number of bits
		- If N == 0: 0
		
		100000	//2^n
	   - 11001	//N	
	   -------
	     00111	//2's complement of N


//==================================================================
// Binary Representation: 2. 2's Complement Range
//==================================================================
https://chortle.ccsu.edu/AssemblyTutorial/Chapter-08/ass08_20.html
8 bits:

0111 1111: 127
...
0000 0001: 1
0000 0000: 0
1111 1111: -1
1111 1110: -2
...
1000 0001: -127
1000 0000: -128


//==================================================================
// Binary Representation: 3. 2's Complement Overflow Detection
//==================================================================
https://chortle.ccsu.edu/AssemblyTutorial/Chapter-08/ass08_23.html

Highest Bit: 
	Carry in and carry out of the are the same: CORRECT
	Different: INCORRECT

 11111 1
  1111 1100
+ 1111 1100     (IN: 1, OUT: 1)
-------------	((-4) + (-4) = -8 CORRECT)
 11111 1000
 
 01111 1
  0111 1100
+ 0111 1100     (IN: 1, OUT: 0)
-------------	(124 + 124 = -8 INCORRECT)
  1111 1000


//==================================================================
// Numerical Types Memory Space
//==================================================================
https://stackoverflow.com/questions/589575/what-does-the-c-standard-state-the-size-of-int-long-type-to-be

#include <limits>
const int min_int = std::numeric_limits<int>::min();
const int max_int = std::numeric_limits<int>::max();


bytes: n
signed: (-|2^(8*n - 1) - 1|) ~ (+|2^(8*n - 1) - 1|)
unsigned: 0 ~ (|2^(8*n) - 1|)

Ex.
bytes: 1
signed: -127 ~ 127
unsigned: 0 ~ 255

							X86			X64
-------------------------------------------------
[integer literal]
char						1			1
unsigned char				1			1

short						2			2
unsigned short				2			2

int							4			4
unsigned int				4			4

long						4			4
unsigned long				4			4

long long					8			8
unsigned long long			8			8

-------------------------------------------------
[float-point]
float						4			4
unsigned float				8			8

double						8			8
unsigned double				8			8

long double					8			8
unsigned long double		8			8

-------------------------------------------------
[array]
char []						1+size		1+size

int []						4*size		4*size

(other integer literals & float-points are of the same as int [])

-------------------------------------------------
[others]
pointer						4			8

string						28			40

struct						sum of all members* + paddings

------------------------------------------------------
[struct padding explaination]
https://docs.microsoft.com/en-us/cpp/cpp/alignment-cpp-declarations?view=vs-2019
struct x_
{
   char a;     // 1 byte
   int b;      // 4 bytes
   short c;    // 2 bytes
   char d;     // 1 byte
} MyStruct;

struct x_
{
   char a;            // 1 byte
   char _pad0[3];     // padding to put 'b' on 4-byte boundary
   int b;            // 4 bytes
   short c;          // 2 bytes
   char d;           // 1 byte
   char _pad1[1];    // padding to make sizeof(x_) multiple of 4
}

//both sizeof(struct x_) are 12

----------------------------------------------------------------------------------------
//You will find some platforms where int is 32 bits(4 Byte), long is 64 bits(8 Byte), and long long is 128 
bits(16 Byte), but it seems very common for sizeof (long) to be 4.
https://stackoverflow.com/questions/900230/difference-between-long-and-int-data-types


//==================================================================
// Bitset
//==================================================================
see "C++ Standard Library - Other - bitset.txt"
